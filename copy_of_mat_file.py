# -*- coding: utf-8 -*-
"""Copy of MAT File

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YKa_ww0yLcPTRGbIZJJQPzkp44R9HJNj
"""

!pip install yfinance alpha_vantage vaderSentiment beautifulsoup4 textblob plotly gnews statsmodels

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# NLP & Sentiment Analysis
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from textblob import TextBlob

# Time Series
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Data Sources
from alpha_vantage.timeseries import TimeSeries
from alpha_vantage.fundamentaldata import FundamentalData
from gnews import GNews
import requests
from bs4 import BeautifulSoup
import json

# Visualization
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns

# ============================================================================
# SECTION 2: CONFIGURATION & API KEYS
# ============================================================================

# API Keys
ALPHA_VANTAGE_API_KEY = "V1BH8AGHLEMEV9Q3"
TWITTER_API_KEY = "mVEjbdMo87xfOUWpVVezqv4zn"
TWITTER_API_SECRET = "eICRrivwo5WmJuwLOJUtFPzfqYQHzgtjqzATXdgKhjK17dVPl"
TWITTER_ACCESS_TOKEN = "1973991042530660352-5Cc30ExAjKAtriD7cEHg0jSZkEW3tN"
TWITTER_ACCESS_SECRET = "2FCaUnHc0hpCmR9JrODO9f3ldoSZZUxqlrvrvZekUft3Ei"

# Initialize sentiment analyzer
vader = SentimentIntensityAnalyzer()

# ============================================================================
# SECTION 3: DATA COLLECTION FUNCTIONS
# ============================================================================

def get_indian_stock_list(top_n=50):
    """
    Get list of top Indian companies
    NSE symbols need .NS suffix for yfinance
    """
    # Top 50 NSE companies (Nifty 50)
    nifty50 = [
        'RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'HINDUNILVR.NS',
        'ICICIBANK.NS', 'BHARTIARTL.NS', 'SBIN.NS', 'ITC.NS', 'LT.NS',
        'BAJFINANCE.NS', 'KOTAKBANK.NS', 'ASIANPAINT.NS', 'HCLTECH.NS', 'AXISBANK.NS',
        'MARUTI.NS', 'WIPRO.NS', 'ULTRACEMCO.NS', 'TITAN.NS', 'SUNPHARMA.NS',
        'NESTLEIND.NS', 'TECHM.NS', 'TATASTEEL.NS', 'BAJAJFINSV.NS', 'POWERGRID.NS',
        'ONGC.NS', 'NTPC.NS', 'M&M.NS', 'ADANIENT.NS', 'JSWSTEEL.NS',
        'TATAMOTORS.NS', 'COALINDIA.NS', 'HINDALCO.NS', 'DIVISLAB.NS', 'INDUSINDBK.NS',
        'DRREDDY.NS', 'CIPLA.NS', 'EICHERMOT.NS', 'GRASIM.NS', 'HEROMOTOCO.NS',
        'BRITANNIA.NS', 'BPCL.NS', 'UPL.NS', 'TATACONSUM.NS', 'APOLLOHOSP.NS',
        'ADANIPORTS.NS', 'SHREECEM.NS', 'HDFCLIFE.NS', 'SBILIFE.NS', 'BAJAJ-AUTO.NS'
    ]
    return nifty50[:top_n]

def fetch_stock_data(symbol, period='2y'):
    """
    Fetch historical stock data using yfinance
    """
    try:
        stock = yf.Ticker(symbol)
        data = stock.history(period=period)
        data['Symbol'] = symbol

        # Get company info
        info = stock.info
        company_name = info.get('longName', symbol)

        return data, company_name
    except Exception as e:
        print(f"Error fetching {symbol}: {e}")
        return None, None

def fetch_alpha_vantage_data(symbol, api_key):
    """
    Fetch data from Alpha Vantage (backup source)
    """
    try:
        # Remove .NS for Alpha Vantage
        clean_symbol = symbol.replace('.NS', '')
        ts = TimeSeries(key=api_key, output_format='pandas')
        data, meta = ts.get_daily(symbol=clean_symbol, outputsize='full')
        return data
    except Exception as e:
        print(f"Alpha Vantage error for {symbol}: {e}")
        return None

def get_news_sentiment(company_name, days=30):
    """
    Fetch and analyze news sentiment using Google News
    """
    try:
        google_news = GNews(language='en', country='IN', period=f'{days}d', max_results=20)
        news = google_news.get_news(company_name)

        sentiments = []

        for article in news:
            title = article.get('title', '')
            description = article.get('description', '')
            text = f"{title}. {description}"

            # VADER sentiment
            vader_score = vader.polarity_scores(text)

            # TextBlob sentiment (additional)
            blob = TextBlob(text)
            textblob_score = blob.sentiment.polarity

            sentiments.append({
                'date': article.get('published date'),
                'title': title,
                'vader_compound': vader_score['compound'],
                'vader_pos': vader_score['pos'],
                'vader_neg': vader_score['neg'],
                'vader_neu': vader_score['neu'],
                'textblob_polarity': textblob_score,
                'url': article.get('url', '')
            })

        return pd.DataFrame(sentiments)

    except Exception as e:
        print(f"News sentiment error: {e}")
        return pd.DataFrame()

def get_financial_news_moneycontrol(company_name):
    """
    Scrape news from Moneycontrol (Indian financial portal)
    """
    try:
        search_url = f"https://www.moneycontrol.com/news/news-all/?search={company_name.replace(' ', '+')}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(search_url, headers=headers, timeout=10)

        soup = BeautifulSoup(response.content, 'html.parser')
        articles = soup.find_all('li', class_='clearfix', limit=10)

        sentiments = []
        for article in articles:
            title_tag = article.find('h2')
            if title_tag:
                title = title_tag.get_text(strip=True)
                vader_score = vader.polarity_scores(title)
                sentiments.append({
                    'title': title,
                    'source': 'Moneycontrol',
                    'vader_compound': vader_score['compound']
                })

        return pd.DataFrame(sentiments)
    except Exception as e:
        print(f"Moneycontrol scraping error: {e}")
        return pd.DataFrame()

def get_economic_times_news(company_name):
    """
    Scrape news from Economic Times
    """
    try:
        search_query = company_name.replace(' ', '%20')
        url = f"https://economictimes.indiatimes.com/topic/{search_query}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)

        soup = BeautifulSoup(response.content, 'html.parser')
        articles = soup.find_all('div', class_='eachStory', limit=15)

        sentiments = []
        for article in articles:
            title_tag = article.find('h3')
            if title_tag:
                title = title_tag.get_text(strip=True)
                vader_score = vader.polarity_scores(title)
                sentiments.append({
                    'title': title,
                    'source': 'Economic Times',
                    'vader_compound': vader_score['compound']
                })

        return pd.DataFrame(sentiments)
    except Exception as e:
        print(f"Economic Times scraping error: {e}")
        return pd.DataFrame()

# ============================================================================
# SECTION 4: FEATURE ENGINEERING
# ============================================================================

def create_technical_indicators(df):
    """
    Create technical indicators for the stock data
    """
    df = df.copy()

    # Moving Averages
    df['SMA_7'] = df['Close'].rolling(window=7).mean()
    df['SMA_21'] = df['Close'].rolling(window=21).mean()
    df['SMA_50'] = df['Close'].rolling(window=50).mean()
    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()

    # MACD
    df['MACD'] = df['EMA_12'] - df['EMA_26']
    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()

    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))

    # Bollinger Bands
    df['BB_middle'] = df['Close'].rolling(window=20).mean()
    bb_std = df['Close'].rolling(window=20).std()
    df['BB_upper'] = df['BB_middle'] + (bb_std * 2)
    df['BB_lower'] = df['BB_middle'] - (bb_std * 2)

    # Volatility
    df['Volatility'] = df['Close'].pct_change().rolling(window=21).std()

    # Volume indicators
    df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()
    df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA']

    # Price momentum
    df['Returns'] = df['Close'].pct_change()
    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))

    return df

def add_sentiment_features(stock_df, sentiment_df):
    """
    Merge sentiment scores with stock data
    """
    if sentiment_df.empty:
        stock_df['sentiment_score'] = 0
        return stock_df

    # Calculate average daily sentiment
    avg_sentiment = sentiment_df['vader_compound'].mean()
    stock_df['sentiment_score'] = avg_sentiment

    return stock_df

# ============================================================================
# SECTION 5: ARIMA PARAMETER SELECTION & MODELING
# ============================================================================

def check_stationarity(data):
    """
    Check if time series is stationary using ADF test
    """
    result = adfuller(data.dropna())
    print(f'ADF Statistic: {result[0]:.4f}')
    print(f'p-value: {result[1]:.4f}')

    if result[1] <= 0.05:
        print("Series is stationary")
        return True
    else:
        print("Series is non-stationary")
        return False

def make_stationary(data, max_diff=2):
    """
    Make time series stationary through differencing
    """
    d = 0
    diff_data = data.copy()

    for i in range(max_diff):
        if check_stationarity(diff_data):
            return diff_data, d
        diff_data = diff_data.diff().dropna()
        d += 1

    return diff_data, d

def find_arima_params_manual(data, max_p=5, max_q=5):
    """
    Manually find optimal ARIMA parameters using AIC/BIC
    """
    print("\nFinding optimal ARIMA parameters...")

    # Check stationarity and get d
    _, d = make_stationary(data)

    # Grid search for p and q
    best_aic = np.inf
    best_params = None

    for p in range(max_p + 1):
        for q in range(max_q + 1):
            try:
                model = ARIMA(data, order=(p, d, q))
                fitted = model.fit()
                aic = fitted.aic

                if aic < best_aic:
                    best_aic = aic
                    best_params = (p, d, q)

            except:
                continue

    print(f"Best ARIMA parameters: {best_params} with AIC: {best_aic:.2f}")
    return best_params

def train_arima_model(train_data, order=(1,1,1)):
    """
    Train ARIMA model
    """
    try:
        model = ARIMA(train_data, order=order)
        fitted_model = model.fit()
        print(f"\nModel Summary:")
        print(fitted_model.summary())
        return fitted_model
    except Exception as e:
        print(f"ARIMA training error: {e}")
        return None

def predict_with_arima(model, steps=30):
    """
    Generate predictions for next 30 days
    """
    try:
        forecast = model.forecast(steps=steps)
        forecast_obj = model.get_forecast(steps=steps)
        conf_int = forecast_obj.conf_int()
        return forecast, conf_int
    except Exception as e:
        print(f"Prediction error: {e}")
        return None, None

def evaluate_model(actual, predicted):
    """
    Calculate model performance metrics
    """
    mse = mean_squared_error(actual, predicted)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(actual, predicted)
    mape = np.mean(np.abs((actual - predicted) / actual)) * 100
    r2 = r2_score(actual, predicted)

    return {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'MAPE': mape,
        'R2': r2
    }

# ============================================================================
# SECTION 6: ENSEMBLE PREDICTION
# ============================================================================

def create_ensemble_prediction(stock_data, sentiment_score, days=30):
    """
    Combine ARIMA with sentiment-adjusted predictions
    """
    # Prepare data
    close_prices = stock_data['Close'].dropna()

    # Split into train/test for validation
    train_size = int(len(close_prices) * 0.9)
    train_data = close_prices[:train_size]
    test_data = close_prices[train_size:]

    # Find optimal ARIMA parameters
    order = find_arima_params_manual(train_data, max_p=5, max_q=5)

    # Train model on full data
    print("\n" + "="*50)
    print("Training ARIMA model on full dataset...")
    print("="*50)
    model = train_arima_model(close_prices, order=order)

    if model is None:
        return None

    # Generate predictions
    print(f"\nGenerating {days}-day forecast...")
    forecast, conf_int = predict_with_arima(model, steps=days)

    if forecast is None:
        return None

    # Apply sentiment adjustment (±5% based on sentiment)
    sentiment_multiplier = 1 + (sentiment_score * 0.05)
    adjusted_forecast = forecast * sentiment_multiplier

    # Create prediction dataframe
    last_date = stock_data.index[-1]
    pred_dates = pd.date_range(start=last_date + timedelta(days=1), periods=days, freq='D')

    predictions_df = pd.DataFrame({
        'Date': pred_dates,
        'Predicted_Price': adjusted_forecast.values,
        'Lower_Bound': conf_int.iloc[:, 0].values * sentiment_multiplier,
        'Upper_Bound': conf_int.iloc[:, 1].values * sentiment_multiplier,
        'ARIMA_Base': forecast.values,
        'Sentiment_Score': sentiment_score
    })

    return predictions_df

# ============================================================================
# SECTION 7: VISUALIZATION
# ============================================================================

def plot_predictions(stock_data, predictions, symbol, company_name):
    """
    Create comprehensive visualization using Plotly
    """
    # Create subplots
    fig = make_subplots(
        rows=3, cols=1,
        subplot_titles=(
            f'{company_name} - Historical & Predicted Prices',
            'Technical Indicators',
            'Volume Analysis'
        ),
        vertical_spacing=0.1,
        row_heights=[0.5, 0.25, 0.25]
    )

    # Plot 1: Historical and Predicted Prices
    fig.add_trace(
        go.Scatter(
            x=stock_data.index[-90:],
            y=stock_data['Close'][-90:],
            name='Historical Price',
            line=dict(color='blue', width=2)
        ),
        row=1, col=1
    )

    fig.add_trace(
        go.Scatter(
            x=predictions['Date'],
            y=predictions['Predicted_Price'],
            name='Predicted Price',
            line=dict(color='red', width=2, dash='dash')
        ),
        row=1, col=1
    )

    # Confidence interval
    fig.add_trace(
        go.Scatter(
            x=predictions['Date'],
            y=predictions['Upper_Bound'],
            name='Upper Bound',
            line=dict(width=0),
            showlegend=False
        ),
        row=1, col=1
    )

    fig.add_trace(
        go.Scatter(
            x=predictions['Date'],
            y=predictions['Lower_Bound'],
            name='Confidence Interval',
            fill='tonexty',
            line=dict(width=0),
            fillcolor='rgba(255,0,0,0.2)'
        ),
        row=1, col=1
    )

    # Plot 2: Technical Indicators
    fig.add_trace(
        go.Scatter(
            x=stock_data.index[-90:],
            y=stock_data['RSI'][-90:],
            name='RSI',
            line=dict(color='purple', width=1)
        ),
        row=2, col=1
    )

    # RSI levels
    fig.add_hline(y=70, line_dash="dash", line_color="red", row=2, col=1)
    fig.add_hline(y=30, line_dash="dash", line_color="green", row=2, col=1)

    # Plot 3: Volume
    fig.add_trace(
        go.Bar(
            x=stock_data.index[-90:],
            y=stock_data['Volume'][-90:],
            name='Volume',
            marker_color='lightblue'
        ),
        row=3, col=1
    )

    # Update layout
    fig.update_layout(
        height=1000,
        title_text=f"{symbol} - Stock Price Prediction (30 Days)",
        showlegend=True,
        hovermode='x unified'
    )

    fig.update_xaxes(title_text="Date", row=3, col=1)
    fig.update_yaxes(title_text="Price (₹)", row=1, col=1)
    fig.update_yaxes(title_text="RSI", row=2, col=1)
    fig.update_yaxes(title_text="Volume", row=3, col=1)

    fig.show()

def plot_sentiment_analysis(sentiment_df):
    """
    Visualize sentiment scores
    """
    if sentiment_df.empty:
        print("No sentiment data to visualize")
        return

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=sentiment_df.index,
        y=sentiment_df['vader_compound'],
        name='Sentiment Score',
        marker_color=sentiment_df['vader_compound'].apply(
            lambda x: 'green' if x > 0 else 'red'
        )
    ))

    fig.update_layout(
        title='News Sentiment Analysis',
        xaxis_title='Article #',
        yaxis_title='Sentiment Score',
        height=400
    )

    fig.show()

# ============================================================================
# SECTION 8: MAIN EXECUTION PIPELINE
# ============================================================================

def predict_stock(symbol, days=30, use_sentiment=True):
    """
    Main function to predict stock prices
    """
    print("="*80)
    print(f"STOCK PREDICTION PIPELINE: {symbol}")
    print("="*80)

    # Step 1: Fetch stock data
    print("\n[1/6] Fetching stock data...")
    stock_data, company_name = fetch_stock_data(symbol, period='2y')

    if stock_data is None or len(stock_data) < 100:
        print(f"Insufficient data for {symbol}")
        return None

    print(f"✓ Fetched {len(stock_data)} days of data for {company_name}")

    # Step 2: Create technical indicators
    print("\n[2/6] Creating technical indicators...")
    stock_data = create_technical_indicators(stock_data)
    print("✓ Technical indicators created")

    # Step 3: Fetch and analyze sentiment
    sentiment_score = 0
    sentiment_df = pd.DataFrame()

    if use_sentiment:
        print("\n[3/6] Analyzing news sentiment...")

        # Google News
        sentiment_df = get_news_sentiment(company_name, days=30)

        # Moneycontrol
        mc_sentiment = get_financial_news_moneycontrol(company_name)

        # Economic Times
        et_sentiment = get_economic_times_news(company_name)

        # Combine all sentiment sources
        all_sentiments = pd.concat([sentiment_df, mc_sentiment, et_sentiment], ignore_index=True)

        if not all_sentiments.empty:
            sentiment_score = all_sentiments['vader_compound'].mean()
            print(f"✓ Average sentiment score: {sentiment_score:.4f}")
            print(f"  Positive: {(all_sentiments['vader_compound'] > 0).sum()} articles")
            print(f"  Negative: {(all_sentiments['vader_compound'] < 0).sum()} articles")
            print(f"  Neutral: {(all_sentiments['vader_compound'] == 0).sum()} articles")

            # Display top headlines
            print("\n  Top Headlines:")
            for idx, row in all_sentiments.head(5).iterrows():
                print(f"  - {row.get('title', 'N/A')[:80]}... (Score: {row['vader_compound']:.2f})")
        else:
            print("⚠ No sentiment data available")
    else:
        print("\n[3/6] Skipping sentiment analysis")

    # Step 4: Add sentiment to stock data
    print("\n[4/6] Merging sentiment with stock data...")
    stock_data = add_sentiment_features(stock_data, all_sentiments if use_sentiment else pd.DataFrame())
    print("✓ Sentiment features added")

    # Step 5: Create predictions
    print("\n[5/6] Training model and generating predictions...")
    predictions = create_ensemble_prediction(stock_data, sentiment_score, days=days)

    if predictions is None:
        print("✗ Prediction failed")
        return None

    print("✓ Predictions generated successfully")

    # Step 6: Visualize results
    print("\n[6/6] Creating visualizations...")
    plot_predictions(stock_data, predictions, symbol, company_name)

    if use_sentiment and not all_sentiments.empty:
        plot_sentiment_analysis(all_sentiments.head(20))

    # Display prediction summary
    print("\n" + "="*80)
    print("PREDICTION SUMMARY")
    print("="*80)
    print(f"\nCurrent Price: ₹{stock_data['Close'].iloc[-1]:.2f}")
    print(f"Predicted Price (Day 1): ₹{predictions['Predicted_Price'].iloc[0]:.2f}")
    print(f"Predicted Price (Day 30): ₹{predictions['Predicted_Price'].iloc[-1]:.2f}")
    print(f"\nExpected Change: {((predictions['Predicted_Price'].iloc[-1] / stock_data['Close'].iloc[-1]) - 1) * 100:.2f}%")
    print(f"Sentiment Adjustment: {(sentiment_score * 5):.2f}%")

    print("\nFirst 5 days predictions:")
    print(predictions.head()[['Date', 'Predicted_Price', 'Lower_Bound', 'Upper_Bound']])

    return {
        'symbol': symbol,
        'company_name': company_name,
        'stock_data': stock_data,
        'predictions': predictions,
        'sentiment_score': sentiment_score,
        'current_price': stock_data['Close'].iloc[-1]
    }

def predict_multiple_stocks(symbols, days=30):
    """
    Predict prices for multiple stocks
    """
    results = {}

    for symbol in symbols:
        try:
            result = predict_stock(symbol, days=days, use_sentiment=True)
            if result:
                results[symbol] = result
            print("\n" + "="*80 + "\n")
        except Exception as e:
            print(f"Error processing {symbol}: {e}")
            continue

    # Create comparison summary
    if results:
        print("\n" + "="*80)
        print("MULTI-STOCK COMPARISON SUMMARY")
        print("="*80)

        comparison_df = pd.DataFrame({
            'Symbol': [r['symbol'] for r in results.values()],
            'Company': [r['company_name'] for r in results.values()],
            'Current Price': [r['current_price'] for r in results.values()],
            'Day 30 Prediction': [r['predictions']['Predicted_Price'].iloc[-1] for r in results.values()],
            'Expected Change %': [
                ((r['predictions']['Predicted_Price'].iloc[-1] / r['current_price']) - 1) * 100
                for r in results.values()
            ],
            'Sentiment': [r['sentiment_score'] for r in results.values()]
        })

        print("\n", comparison_df.to_string(index=False))

        # Plot comparison
        fig = go.Figure()

        fig.add_trace(go.Bar(
            x=comparison_df['Symbol'],
            y=comparison_df['Expected Change %'],
            marker_color=comparison_df['Expected Change %'].apply(
                lambda x: 'green' if x > 0 else 'red'
            ),
            text=comparison_df['Expected Change %'].round(2),
            textposition='outside'
        ))

        fig.update_layout(
            title='30-Day Expected Price Change Comparison',
            xaxis_title='Stock Symbol',
            yaxis_title='Expected Change (%)',
            height=500
        )

        fig.show()

    return results

# ============================================================================
# SECTION 9: EXAMPLE USAGE
# ============================================================================

# Example 1: Single stock prediction
print("Starting prediction for a single stock...")
result = predict_stock('', days=30, use_sentiment=True)

# Example 2: Multiple stocks prediction
# Uncomment to run for multiple stocks
"""
stock_symbols = ['RELIANCE.NS', 'TCS.NS', 'INFY.NS', 'HDFCBANK.NS', 'ICICIBANK.NS']
results = predict_multiple_stocks(stock_symbols, days=30)
"""

# Example 3: All Nifty 50 stocks
# WARNING: This will take significant time and API calls
"""
nifty50_symbols = get_indian_stock_list(50)
all_results = predict_multiple_stocks(nifty50_symbols, days=30)

# Save results to CSV
predictions_summary = pd.DataFrame({
    'Symbol': [r['symbol'] for r in all_results.values()],
    'Company': [r['company_name'] for r in all_results.values()],
    'Current_Price': [r['current_price'] for r in all_results.values()],
    'Day30_Prediction': [r['predictions']['Predicted_Price'].iloc[-1] for r in all_results.values()],
    'Expected_Change_Percent': [
        ((r['predictions']['Predicted_Price'].iloc[-1] / r['current_price']) - 1) * 100
        for r in all_results.values()
    ]
})

predictions_summary.to_csv('nifty50_predictions.csv', index=False)
print("\n✓ Predictions saved to nifty50_predictions.csv")
"""

# ============================================================================
# SECTION 9: EXAMPLE USAGE
# ============================================================================

# Example 1: Single stock prediction
# print("Starting prediction for a single stock...")
# result = predict_stock('AXISBANK.NS', days=30, use_sentiment=True)

# Example 2: Multiple stocks prediction
# print("Starting prediction for multiple stocks...")
# stock_symbols = ['RELIANCE.NS', 'TCS.NS', 'INFY.NS', 'HDFCBANK.NS', 'ICICIBANK.NS']
# results = predict_multiple_stocks(stock_symbols, days=7) # Predict for the next 7 days


# Example 3: All Nifty 50 stocks
print("Starting prediction for all Nifty 50 stocks...")
# WARNING: This will take significant time and API calls

nifty50_symbols = get_indian_stock_list(50)
all_results = predict_multiple_stocks(nifty50_symbols, days=7) # Predict for the next 7 days

# Save results to CSV
if all_results:
    predictions_summary = pd.DataFrame({
        'Symbol': [r['symbol'] for r in all_results.values()],
        'Company': [r['company_name'] for r in all_results.values()],
        'Current_Price': [r['current_price'] for r in all_results.values()],
        'Day7_Prediction': [r['predictions']['Predicted_Price'].iloc[-1] for r in all_results.values()],
        'Expected_Change_Percent': [
            ((r['predictions']['Predicted_Price'].iloc[-1] / r['current_price']) - 1) * 100
            for r in all_results.values()
        ]
    })

    predictions_summary.to_csv('nifty50_7day_predictions.csv', index=False)
    print("\n✓ Predictions saved to nifty50_7day_predictions.csv")

    # Find the stock with the highest positive expected change
    best_performer = predictions_summary[predictions_summary['Expected_Change_Percent'] > 0].sort_values(by='Expected_Change_Percent', ascending=False).head(1)

    if not best_performer.empty:
        print("\n" + "="*80)
        print("BEST PERFORMING STOCK (Next 7 Days)")
        print("="*80)
        print(best_performer.to_string(index=False))
    else:
        print("\nNo stocks predicted to have a positive change in the next 7 days.")

# Include necessary functions from previous cells
def get_indian_stock_list(top_n=50):
    """
    Get list of top Indian companies
    NSE symbols need .NS suffix for yfinance
    """
    # Top 50 NSE companies (Nifty 50)
    nifty50 = [
        'RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'HINDUNILVR.NS',
        'ICICIBANK.NS', 'BHARTIARTL.NS', 'SBIN.NS', 'ITC.NS', 'LT.NS',
        'BAJFINANCE.NS', 'KOTAKBANK.NS', 'ASIANPAINT.NS', 'HCLTECH.NS', 'AXISBANK.NS',
        'MARUTI.NS', 'WIPRO.NS', 'ULTRACEMCO.NS', 'TITAN.NS', 'SUNPHARMA.NS',
        'NESTLEIND.NS', 'TECHM.NS', 'TATASTEEL.NS', 'BAJAJFINSV.NS', 'POWERGRID.NS',
        'ONGC.NS', 'NTPC.NS', 'M&M.NS', 'ADANIENT.NS', 'JSWSTEEL.NS',
        'TATAMOTORS.NS', 'COALINDIA.NS', 'HINDALCO.NS', 'DIVISLAB.NS', 'INDUSINDBK.NS',
        'DRREDDY.NS', 'CIPLA.NS', 'EICHERMOT.NS', 'GRASIM.NS', 'HEROMOTOCO.NS',
        'BRITANNIA.NS', 'BPCL.NS', 'UPL.NS', 'TATACONSUM.NS', 'APOLLOHOSP.NS',
        'ADANIPORTS.NS', 'SHREECEM.NS', 'HDFCLIFE.NS', 'SBILIFE.NS', 'BAJAJ-AUTO.NS'
    ]
    return nifty50[:top_n]

def predict_multiple_stocks(symbols, days=30):
    """
    Predict prices for multiple stocks
    """
    results = {}

    for symbol in symbols:
        try:
            result = predict_stock(symbol, days=days, use_sentiment=True)
            if result:
                results[symbol] = result
            print("\n" + "="*80 + "\n")
        except Exception as e:
            print(f"Error processing {symbol}: {e}")
            continue

    # Create comparison summary
    if results:
        print("\n" + "="*80)
        print("MULTI-STOCK COMPARISON SUMMARY")
        print("="*80)

        comparison_df = pd.DataFrame({
            'Symbol': [r['symbol'] for r in results.values()],
            'Company': [r['company_name'] for r in results.values()],
            'Current Price': [r['current_price'] for r in results.values()],
            'Day_Prediction': [r['predictions']['Predicted_Price'].iloc[-1] for r in results.values()],
            'Expected_Change_Percent': [
                ((r['predictions']['Predicted_Price'].iloc[-1] / r['current_price']) - 1) * 100
                for r in results.values()
            ],
            'Sentiment': [r['sentiment_score'] for r in results.values()]
        })

        print("\n", comparison_df.to_string(index=False))

        # Plot comparison
        fig = go.Figure()

        fig.add_trace(go.Bar(
            x=comparison_df['Symbol'],
            y=comparison_df['Expected_Change_Percent'],
            marker_color=comparison_df['Expected_Change_Percent'].apply(
                lambda x: 'green' if x > 0 else 'red'
            ),
            text=comparison_df['Expected_Change_Percent'].round(2),
            textposition='outside'
        ))

        fig.update_layout(
            title=f'{days}-Day Expected Price Change Comparison',
            xaxis_title='Stock Symbol',
            yaxis_title='Expected Change (%)',
            height=500
        )

        fig.show()

    return results


# ============================================================================
# SECTION 9: EXAMPLE USAGE
# ============================================================================

# Example 1: Single stock prediction
# print("Starting prediction for a single stock...")
# result = predict_stock('AXISBANK.NS', days=30, use_sentiment=True)

# Example 2: Multiple stocks prediction
# print("Starting prediction for multiple stocks...")
# stock_symbols = ['RELIANCE.NS', 'TCS.NS', 'INFY.NS', 'HDFCBANK.NS', 'ICICIBANK.NS']
# results = predict_multiple_stocks(stock_symbols, days=7) # Predict for the next 7 days


# Example 3: All Nifty 50 stocks
print("Starting prediction for all Nifty 50 stocks...")
# WARNING: This will take significant time and API calls

nifty50_symbols = get_indian_stock_list(50)
all_results = predict_multiple_stocks(nifty50_symbols, days=7) # Predict for the next 7 days

# Save results to CSV
if all_results:
    predictions_summary = pd.DataFrame({
        'Symbol': [r['symbol'] for r in all_results.values()],
        'Company': [r['company_name'] for r in all_results.values()],
        'Current_Price': [r['current_price'] for r in all_results.values()],
        'Day7_Prediction': [r['predictions']['Predicted_Price'].iloc[-1] for r in all_results.values()],
        'Expected_Change_Percent': [
            ((r['predictions']['Predicted_Price'].iloc[-1] / r['current_price']) - 1) * 100
            for r in all_results.values()
        ]
    })

    predictions_summary.to_csv('nifty50_7day_predictions.csv', index=False)
    print("\n✓ Predictions saved to nifty50_7day_predictions.csv")

    # Find the stock with the highest positive expected change
    best_performer = predictions_summary[predictions_summary['Expected_Change_Percent'] > 0].sort_values(by='Expected_Change_Percent', ascending=False).head(1)

    if not best_performer.empty:
        print("\n" + "="*80)
        print("BEST PERFORMING STOCK (Next 7 Days)")
        print("="*80)
        print(best_performer.to_string(index=False))
    else:
        print("\nNo stocks predicted to have a positive change in the next 7 days.")

# Include necessary functions and imports from previous cells
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# NLP & Sentiment Analysis
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from textblob import TextBlob

# Time Series
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Data Sources
from alpha_vantage.timeseries import TimeSeries
from alpha_vantage.fundamentaldata import FundamentalData
from gnews import GNews
import requests
from bs4 import BeautifulSoup
import json

# Visualization
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns

# Initialize sentiment analyzer (from SECTION 2)
vader = SentimentIntensityAnalyzer()
ALPHA_VANTAGE_API_KEY = "V1BH8AGHLEMEV9Q3" # Ensure you replace with your actual key


# Data Collection Functions (from SECTION 3)
def get_indian_stock_list(top_n=50):
    """
    Get list of top Indian companies
    NSE symbols need .NS suffix for yfinance
    """
    # Top 50 NSE companies (Nifty 50)
    nifty50 = [
        'RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'HINDUNILVR.NS',
        'ICICIBANK.NS', 'BHARTIARTL.NS', 'SBIN.NS', 'ITC.NS', 'LT.NS',
        'BAJFINANCE.NS', 'KOTAKBANK.NS', 'ASIANPAINT.NS', 'HCLTECH.NS', 'AXISBANK.NS',
        'MARUTI.NS', 'WIPRO.NS', 'ULTRACEMCO.NS', 'TITAN.NS', 'SUNPHARMA.NS',
        'NESTLEIND.NS', 'TECHM.NS', 'TATASTEEL.NS', 'BAJAJFINSV.NS', 'POWERGRID.NS',
        'ONGC.NS', 'NTPC.NS', 'M&M.NS', 'ADANIENT.NS', 'JSWSTEEL.NS',
        'TATAMOTORS.NS', 'COALINDIA.NS', 'HINDALCO.NS', 'DIVISLAB.NS', 'INDUSINDBK.NS',
        'DRREDDY.NS', 'CIPLA.NS', 'EICHERMOT.NS', 'GRASIM.NS', 'HEROMOTOCO.NS',
        'BRITANNIA.NS', 'BPCL.NS', 'UPL.NS', 'TATACONSUM.NS', 'APOLLOHOSP.NS',
        'ADANIPORTS.NS', 'SHREECEM.NS', 'HDFCLIFE.NS', 'SBILIFE.NS', 'BAJAJ-AUTO.NS'
    ]
    return nifty50[:top_n]

def fetch_stock_data(symbol, period='2y'):
    """
    Fetch historical stock data using yfinance
    """
    try:
        stock = yf.Ticker(symbol)
        data = stock.history(period=period)
        data['Symbol'] = symbol

        # Get company info
        info = stock.info
        company_name = info.get('longName', symbol)

        return data, company_name
    except Exception as e:
        print(f"Error fetching {symbol}: {e}")
        return None, None

def fetch_alpha_vantage_data(symbol, api_key):
    """
    Fetch data from Alpha Vantage (backup source)
    """
    try:
        # Remove .NS for Alpha Vantage
        clean_symbol = symbol.replace('.NS', '')
        ts = TimeSeries(key=api_key, output_format='pandas')
        data, meta = ts.get_daily(symbol=clean_symbol, outputsize='full')
        return data
    except Exception as e:
        print(f"Alpha Vantage error for {symbol}: {e}")
        return None

def get_news_sentiment(company_name, days=30):
    """
    Fetch and analyze news sentiment using Google News
    """
    try:
        google_news = GNews(language='en', country='IN', period=f'{days}d', max_results=20)
        news = google_news.get_news(company_name)

        sentiments = []

        for article in news:
            title = article.get('title', '')
            description = article.get('description', '')
            text = f"{title}. {description}"

            # VADER sentiment
            vader_score = vader.polarity_scores(text)

            # TextBlob sentiment (additional)
            blob = TextBlob(text)
            textblob_score = blob.sentiment.polarity

            sentiments.append({
                'date': article.get('published date'),
                'title': title,
                'vader_compound': vader_score['compound'],
                'vader_pos': vader_score['pos'],
                'vader_neg': vader_score['neg'],
                'vader_neu': vader_score['neu'],
                'textblob_polarity': textblob_score,
                'url': article.get('url', '')
            })

        return pd.DataFrame(sentiments)

    except Exception as e:
        print(f"News sentiment error: {e}")
        return pd.DataFrame()

def get_financial_news_moneycontrol(company_name):
    """
    Scrape news from Moneycontrol (Indian financial portal)
    """
    try:
        search_url = f"https://www.moneycontrol.com/news/news-all/?search={company_name.replace(' ', '+')}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(search_url, headers=headers, timeout=10)

        soup = BeautifulSoup(response.content, 'html.parser')
        articles = soup.find_all('li', class_='clearfix', limit=10)

        sentiments = []
        for article in articles:
            title_tag = article.find('h2')
            if title_tag:
                title = title_tag.get_text(strip=True)
                vader_score = vader.polarity_scores(title)
                sentiments.append({
                    'title': title,
                    'source': 'Moneycontrol',
                    'vader_compound': vader_score['compound']
                })

        return pd.DataFrame(sentiments)
    except Exception as e:
        print(f"Moneycontrol scraping error: {e}")
        return pd.DataFrame()

def get_economic_times_news(company_name):
    """
    Scrape news from Economic Times
    """
    try:
        search_query = company_name.replace(' ', '%20')
        url = f"https://economictimes.indiatimes.com/topic/{search_query}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)

        soup = BeautifulSoup(response.content, 'html.parser')
        articles = soup.find_all('div', class_='eachStory', limit=15)

        sentiments = []
        for article in articles:
            title_tag = article.find('h3')
            if title_tag:
                title = title_tag.get_text(strip=True)
                vader_score = vader.polarity_scores(title)
                sentiments.append({
                    'title': title,
                    'source': 'Economic Times',
                    'vader_compound': vader_score['compound']
                })

        return pd.DataFrame(sentiments)
    except Exception as e:
        print(f"Economic Times scraping error: {e}")
        return pd.DataFrame()

# Feature Engineering (from SECTION 4)
def create_technical_indicators(df):
    """
    Create technical indicators for the stock data
    """
    df = df.copy()

    # Moving Averages
    df['SMA_7'] = df['Close'].rolling(window=7).mean()
    df['SMA_21'] = df['Close'].rolling(window=21).mean()
    df['SMA_50'] = df['Close'].rolling(window=50).mean()
    df['EMA_12'] = df['Close'].ewm(span=12, adjust=False).mean()
    df['EMA_26'] = df['Close'].ewm(span=26, adjust=False).mean()

    # MACD
    df['MACD'] = df['EMA_12'] - df['EMA_26']
    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()

    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))

    # Bollinger Bands
    df['BB_middle'] = df['Close'].rolling(window=20).mean()
    bb_std = df['Close'].rolling(window=20).std()
    df['BB_upper'] = df['BB_middle'] + (bb_std * 2)
    df['BB_lower'] = df['BB_middle'] - (bb_std * 2)

    # Volatility
    df['Volatility'] = df['Close'].pct_change().rolling(window=21).std()

    # Volume indicators
    df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()
    df['Volume_Ratio'] = df['Volume'] / df['Volume_SMA']

    # Price momentum
    df['Returns'] = df['Close'].pct_change()
    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))

    return df

def add_sentiment_features(stock_df, sentiment_df):
    """
    Merge sentiment scores with stock data
    """
    if sentiment_df.empty:
        stock_df['sentiment_score'] = 0
        return stock_df

    # Calculate average daily sentiment
    # Group sentiment_df by date and calculate the mean compound score
    sentiment_df['date'] = pd.to_datetime(sentiment_df['date']).dt.date
    stock_df.index = pd.to_datetime(stock_df.index).date
    daily_sentiment = sentiment_df.groupby('date')['vader_compound'].mean()

    # Merge with stock data, forward fill missing dates
    stock_df['sentiment_score'] = stock_df.index.map(daily_sentiment).fillna(method='ffill')
    stock_df['sentiment_score'] = stock_df['sentiment_score'].fillna(0) # Fill initial NaNs with 0


    return stock_df


# ARIMA Parameter Selection & Modeling (from SECTION 5)
def check_stationarity(data):
    """
    Check if time series is stationary using ADF test
    """
    result = adfuller(data.dropna())
    print(f'ADF Statistic: {result[0]:.4f}')
    print(f'p-value: {result[1]:.4f}')

    if result[1] <= 0.05:
        print("Series is stationary")
        return True
    else:
        print("Series is non-stationary")
        return False

def make_stationary(data, max_diff=2):
    """
    Make time series stationary through differencing
    """
    d = 0
    diff_data = data.copy()

    for i in range(max_diff):
        if check_stationarity(diff_data):
            return diff_data, d
        diff_data = diff_data.diff().dropna()
        d += 1

    return diff_data, d

def find_arima_params_manual(data, max_p=5, max_q=5):
    """
    Manually find optimal ARIMA parameters using AIC/BIC
    """
    print("\nFinding optimal ARIMA parameters...")

    # Check stationarity and get d
    _, d = make_stationary(data)

    # Grid search for p and q
    best_aic = np.inf
    best_params = None

    for p in range(max_p + 1):
        for q in range(max_q + 1):
            try:
                model = ARIMA(data, order=(p, d, q))
                fitted = model.fit()
                aic = fitted.aic

                if aic < best_aic:
                    best_aic = aic
                    best_params = (p, d, q)

            except:
                continue

    print(f"Best ARIMA parameters: {best_params} with AIC: {best_aic:.2f}")
    return best_params

def train_arima_model(train_data, order=(1,1,1)):
    """
    Train ARIMA model
    """
    try:
        model = ARIMA(train_data, order=order)
        fitted_model = model.fit()
        print(f"\nModel Summary:")
        print(fitted_model.summary())
        return fitted_model
    except Exception as e:
        print(f"ARIMA training error: {e}")
        return None

def predict_with_arima(model, steps=30):
    """
    Generate predictions for next 30 days
    """
    try:
        forecast = model.forecast(steps=steps)
        forecast_obj = model.get_forecast(steps=steps)
        conf_int = forecast_obj.conf_int()
        return forecast, conf_int
    except Exception as e:
        print(f"Prediction error: {e}")
        return None, None

def evaluate_model(actual, predicted):
    """
    Calculate model performance metrics
    """
    mse = mean_squared_error(actual, predicted)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(actual, predicted)
    mape = np.mean(np.abs((actual - predicted) / actual)) * 100
    r2 = r2_score(actual, predicted)

    return {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'MAPE': mape,
        'R2': r2
    }

# Ensemble Prediction (from SECTION 6)
def create_ensemble_prediction(stock_data, sentiment_score, days=30):
    """
    Combine ARIMA with sentiment-adjusted predictions
    """
    # Prepare data
    close_prices = stock_data['Close'].dropna()

    # Split into train/test for validation
    train_size = int(len(close_prices) * 0.9)
    train_data = close_prices[:train_size]
    test_data = close_prices[train_size:]

    # Find optimal ARIMA parameters
    order = find_arima_params_manual(train_data, max_p=5, max_q=5)

    # Train model on full data
    print("\n" + "="*50)
    print("Training ARIMA model on full dataset...")
    print("="*50)
    model = train_arima_model(close_prices, order=order)

    if model is None:
        return None

    # Generate predictions
    print(f"\nGenerating {days}-day forecast...")
    forecast, conf_int = predict_with_arima(model, steps=days)

    if forecast is None:
        return None

    # Apply sentiment adjustment (±5% based on sentiment)
    sentiment_multiplier = 1 + (sentiment_score * 0.05)
    adjusted_forecast = forecast * sentiment_multiplier

    # Create prediction dataframe
    last_date = stock_data.index[-1]
    # Ensure last_date is a datetime object
    if isinstance(last_date, pd.Timestamp):
        start_date = last_date + timedelta(days=1)
    else:
        start_date = datetime.strptime(str(last_date), '%Y-%m-%d') + timedelta(days=1) # Assuming date format

    pred_dates = pd.date_range(start=start_date, periods=days, freq='D')

    predictions_df = pd.DataFrame({
        'Date': pred_dates,
        'Predicted_Price': adjusted_forecast.values,
        'Lower_Bound': conf_int.iloc[:, 0].values * sentiment_multiplier,
        'Upper_Bound': conf_int.iloc[:, 1].values * sentiment_multiplier,
        'ARIMA_Base': forecast.values,
        'Sentiment_Score': sentiment_score
    })

    return predictions_df

# Visualization (from SECTION 7)
def plot_predictions(stock_data, predictions, symbol, company_name):
    """
    Create comprehensive visualization using Plotly
    """
    # Create subplots
    fig = make_subplots(
        rows=3, cols=1,
        subplot_titles=(
            f'{company_name} - Historical & Predicted Prices',
            'Technical Indicators',
            'Volume Analysis'
        ),
        vertical_spacing=0.1,
        row_heights=[0.5, 0.25, 0.25]
    )

    # Plot 1: Historical and Predicted Prices
    fig.add_trace(
        go.Scatter(
            x=stock_data.index[-90:],
            y=stock_data['Close'][-90:],
            name='Historical Price',
            line=dict(color='blue', width=2)
        ),
        row=1, col=1
    )

    fig.add_trace(
        go.Scatter(
            x=predictions['Date'],
            y=predictions['Predicted_Price'],
            name='Predicted Price',
            line=dict(color='red', width=2, dash='dash')
        ),
        row=1, col=1
    )

    # Confidence interval
    fig.add_trace(
        go.Scatter(
            x=predictions['Date'],
            y=predictions['Upper_Bound'],
            name='Upper Bound',
            line=dict(width=0),
            showlegend=False
        ),
        row=1, col=1
    )

    fig.add_trace(
        go.Scatter(
            x=predictions['Date'],
            y=predictions['Lower_Bound'],
            name='Confidence Interval',
            fill='tonexty',
            line=dict(width=0),
            fillcolor='rgba(255,0,0,0.2)'
        ),
        row=1, col=1
    )

    # Plot 2: Technical Indicators
    fig.add_trace(
        go.Scatter(
            x=stock_data.index[-90:],
            y=stock_data['RSI'][-90:],
            name='RSI',
            line=dict(color='purple', width=1)
        ),
        row=2, col=1
    )

    # RSI levels
    fig.add_hline(y=70, line_dash="dash", line_color="red", row=2, col=1)
    fig.add_hline(y=30, line_dash="dash", line_color="green", row=2, col=1)

    # Plot 3: Volume
    fig.add_trace(
        go.Bar(
            x=stock_data.index[-90:],
            y=stock_data['Volume'][-90:],
            name='Volume',
            marker_color='lightblue'
        ),
        row=3, col=1
    )

    # Update layout
    fig.update_layout(
        height=1000,
        title_text=f"{symbol} - Stock Price Prediction ({predictions.shape[0]} Days)",
        showlegend=True,
        hovermode='x unified'
    )

    fig.update_xaxes(title_text="Date", row=3, col=1)
    fig.update_yaxes(title_text="Price (₹)", row=1, col=1)
    fig.update_yaxes(title_text="RSI", row=2, col=1)
    fig.update_yaxes(title_text="Volume", row=3, col=1)

    fig.show()

def plot_sentiment_analysis(sentiment_df):
    """
    Visualize sentiment scores
    """
    if sentiment_df.empty:
        print("No sentiment data to visualize")
        return

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=sentiment_df.index,
        y=sentiment_df['vader_compound'],
        name='Sentiment Score',
        marker_color=sentiment_df['vader_compound'].apply(
            lambda x: 'green' if x > 0 else 'red'
        )
    ))

    fig.update_layout(
        title='News Sentiment Analysis',
        xaxis_title='Article #',
        yaxis_title='Sentiment Score',
        height=400
    )

    fig.show()


# Main Execution Pipeline (from SECTION 8)
def predict_stock(symbol, days=30, use_sentiment=True):
    """
    Main function to predict stock prices
    """
    print("="*80)
    print(f"STOCK PREDICTION PIPELINE: {symbol}")
    print("="*80)

    # Step 1: Fetch stock data
    print("\n[1/6] Fetching stock data...")
    stock_data, company_name = fetch_stock_data(symbol, period='2y')

    if stock_data is None or len(stock_data) < 100:
        print(f"Insufficient data for {symbol}")
        return None

    print(f"✓ Fetched {len(stock_data)} days of data for {company_name}")

    # Step 2: Create technical indicators
    print("\n[2/6] Creating technical indicators...")
    stock_data = create_technical_indicators(stock_data)
    print("✓ Technical indicators created")

    # Step 3: Fetch and analyze sentiment
    sentiment_score = 0
    all_sentiments = pd.DataFrame()

    if use_sentiment:
        print("\n[3/6] Analyzing news sentiment...")

        # Google News
        sentiment_df_google = get_news_sentiment(company_name, days=30)

        # Moneycontrol
        mc_sentiment = get_financial_news_moneycontrol(company_name)

        # Economic Times
        et_sentiment = get_economic_times_news(company_name)

        # Combine all sentiment sources
        all_sentiments = pd.concat([sentiment_df_google, mc_sentiment, et_sentiment], ignore_index=True)

        if not all_sentiments.empty:
            sentiment_score = all_sentiments['vader_compound'].mean()
            print(f"✓ Average sentiment score: {sentiment_score:.4f}")
            print(f"  Positive: {(all_sentiments['vader_compound'] > 0).sum()} articles")
            print(f"  Negative: {(all_sentiments['vader_compound'] < 0).sum()} articles")
            print(f"  Neutral: {(all_sentiments['vader_compound'] == 0).sum()} articles")

            # Display top headlines
            print("\n  Top Headlines:")
            for idx, row in all_sentiments.head(5).iterrows():
                print(f"  - {row.get('title', 'N/A')[:80]}... (Score: {row['vader_compound']:.2f})")
        else:
            print("⚠ No sentiment data available")
    else:
        print("\n[3/6] Skipping sentiment analysis")


    # Step 4: Add sentiment to stock data
    print("\n[4/6] Merging sentiment with stock data...")
    stock_data = add_sentiment_features(stock_data, all_sentiments if use_sentiment else pd.DataFrame())
    print("✓ Sentiment features added")


    # Step 5: Create predictions
    print("\n[5/6] Training model and generating predictions...")
    predictions = create_ensemble_prediction(stock_data, sentiment_score, days=days)

    if predictions is None:
        print("✗ Prediction failed")
        return None

    print("✓ Predictions generated successfully")

    # Step 6: Visualize results
    print("\n[6/6] Creating visualizations...")
    plot_predictions(stock_data, predictions, symbol, company_name)

    if use_sentiment and not all_sentiments.empty:
        plot_sentiment_analysis(all_sentiments.head(20))


    # Display prediction summary
    print("\n" + "="*80)
    print("PREDICTION SUMMARY")
    print("="*80)
    print(f"\nCurrent Price: ₹{stock_data['Close'].iloc[-1]:.2f}")
    print(f"Predicted Price (Day 1): ₹{predictions['Predicted_Price'].iloc[0]:.2f}")
    print(f"Predicted Price (Day {days}): ₹{predictions['Predicted_Price'].iloc[-1]:.2f}")
    print(f"\nExpected Change: {((predictions['Predicted_Price'].iloc[-1] / stock_data['Close'].iloc[-1]) - 1) * 100:.2f}%")
    print(f"Sentiment Adjustment: {(sentiment_score * 5):.2f}% (assuming max +/- 5% influence)")

    print("\nFirst 5 days predictions:")
    print(predictions.head()[['Date', 'Predicted_Price', 'Lower_Bound', 'Upper_Bound']])


    return {
        'symbol': symbol,
        'company_name': company_name,
        'stock_data': stock_data,
        'predictions': predictions,
        'sentiment_score': sentiment_score,
        'current_price': stock_data['Close'].iloc[-1]
    }

def predict_multiple_stocks(symbols, days=30):
    """
    Predict prices for multiple stocks
    """
    results = {}

    for symbol in symbols:
        try:
            result = predict_stock(symbol, days=days, use_sentiment=True)
            if result:
                results[symbol] = result
            print("\n" + "="*80 + "\n")
        except Exception as e:
            print(f"Error processing {symbol}: {e}")
            continue

    # Create comparison summary
    if results:
        print("\n" + "="*80)
        print("MULTI-STOCK COMPARISON SUMMARY")
        print("="*80)

        comparison_df = pd.DataFrame({
            'Symbol': [r['symbol'] for r in results.values()],
            'Company': [r['company_name'] for r in results.values()],
            'Current Price': [r['current_price'] for r in results.values()],
            f'Day{days}_Prediction': [r['predictions']['Predicted_Price'].iloc[-1] for r in results.values()],
            'Expected_Change_Percent': [
                ((r['predictions']['Predicted_Price'].iloc[-1] / r['current_price']) - 1) * 100
                for r in results.values()
            ],
            'Sentiment': [r['sentiment_score'] for r in results.values()]
        })

        print("\n", comparison_df.to_string(index=False))

        # Plot comparison
        fig = go.Figure()

        fig.add_trace(go.Bar(
            x=comparison_df['Symbol'],
            y=comparison_df['Expected_Change_Percent'],
            marker_color=comparison_df['Expected_Change_Percent'].apply(
                lambda x: 'green' if x > 0 else 'red'
            )
        ))

        fig.update_layout(
            title=f'{days}-Day Expected Price Change Comparison',
            xaxis_title='Stock Symbol',
            yaxis_title='Expected Change (%)',
            height=500
        )

        fig.show()

    return results


# ============================================================================
# SECTION 9: EXAMPLE USAGE
# ============================================================================

# Example 1: Single stock prediction
# print("Starting prediction for a single stock...")
# result = predict_stock('AXISBANK.NS', days=30, use_sentiment=True)

# Example 2: Multiple stocks prediction
# print("Starting prediction for multiple stocks...")
# stock_symbols = ['RELIANCE.NS', 'TCS.NS', 'INFY.NS', 'HDFCBANK.NS', 'ICICIBANK.NS']
# results = predict_multiple_stocks(stock_symbols, days=7) # Predict for the next 7 days


# Example 3: All Nifty 50 stocks
print("Starting prediction for all Nifty 50 stocks...")
# WARNING: This will take significant time and API calls

nifty50_symbols = get_indian_stock_list(50)
all_results = predict_multiple_stocks(nifty50_symbols, days=7) # Predict for the next 7 days

# Save results to CSV
if all_results:
    predictions_summary = pd.DataFrame({
        'Symbol': [r['symbol'] for r in all_results.values()],
        'Company': [r['company_name'] for r in all_results.values()],
        'Current_Price': [r['current_price'] for r in all_results.values()],
        'Day7_Prediction': [r['predictions']['Predicted_Price'].iloc[-1] for r in all_results.values()],
        'Expected_Change_Percent': [
            ((r['predictions']['Predicted_Price'].iloc[-1] / r['current_price']) - 1) * 100
            for r in all_results.values()
        ]
    })

    predictions_summary.to_csv('nifty50_7day_predictions.csv', index=False)
    print("\n✓ Predictions saved to nifty50_7day_predictions.csv")

    # Find the stock with the highest positive expected change
    best_performer = predictions_summary[predictions_summary['Expected_Change_Percent'] > 0].sort_values(by='Expected_Change_Percent', ascending=False).head(1)

    if not best_performer.empty:
        print("\n" + "="*80)
        print("BEST PERFORMING STOCK (Next 7 Days)")
        print("="*80)
        print(best_performer.to_string(index=False))
    else:
        print("\nNo stocks predicted to have a positive change in the next 7 days.")